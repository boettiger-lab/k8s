apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemotron
  namespace: llm
  labels:
    k8s-app: vllm-nimbus-nemotron
spec:
  replicas: 1
  selector:
    matchLabels:
      k8s-app: vllm-nimbus-nemotron
  template:
    metadata:
      labels:
        k8s-app: vllm-nimbus-nemotron
    spec:
      runtimeClassName: nvidia
      containers:
      - name: vllm
#        image: nvcr.io/nvidia/vllm:25.11-py3
        image: ghcr.io/nvidia-ai-iot/vllm:latest-jetson-thor
        imagePullPolicy: IfNotPresent
        ports:
        - containerPort: 8000
          name: http
        env:
        - name: HF_HOME
          value: /models
        - name: TRANSFORMERS_CACHE
          value: /models/hub
        - name: HF_TOKEN
          valueFrom:
            secretKeyRef:
              name: huggingface-token
              key: token
              optional: true
        - name: VLLM_API_KEY
          valueFrom:
            secretKeyRef:
              name: vllm-api-key
              key: api-key
        - name: OMP_NUM_THREADS
          value: "4"
#        - name: VLLM_LOGGING_LEVEL
#          value: "DEBUG"
        args:
        - "vllm"
        - "serve"
        - "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16"
        - "--served-model-name"
        - "nemotron"
        - "--dtype"
        - "auto"
        - "--trust-remote-code"
        - "--enable-auto-tool-choice"
        - "--tool-call-parser"
        - "qwen3_coder"
        - "--reasoning-parser-plugin"
        - "/reasoning-parser/nano_v3_reasoning_parser.py"
        - "--reasoning-parser"
        - "nano_v3"
        - "--tensor-parallel-size"
        - "1"
        - "--max-model-len"
        - "262144"
        - "--gpu-memory-utilization"
        - "0.65"
        volumeMounts:
        - name: reasoning-parser
          mountPath: /reasoning-parser
          readOnly: true
        - name: dshm
          mountPath: /dev/shm
        - name: model-volume
          mountPath: /models
          readOnly: false
        resources:
          requests:
            cpu: 4
            memory: 32Gi
            nvidia.com/gpu: 1
          limits:
            cpu: 4
            memory: 32Gi
            nvidia.com/gpu: 1
        securityContext:
          capabilities:
            add:
            - IPC_LOCK
      volumes:
      - name: reasoning-parser
        hostPath:
          path: /home/cboettig/Documents/github/boettiger-lab/k8s/vllm/nimbus
          type: Directory
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: 1Gi
      - name: model-volume
        persistentVolumeClaim:
          claimName: vllm-pvc
